<!DOCTYPE html>
<html lang="en-gb">
<head>
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> How We Lost Control and Learned Nothing | Robert Marshall</title>
  <link rel = 'canonical' href = 'https://robertmarshall.xyz/writings/how-we-lost-control-and-learned-nothing/'>
  <meta name="description" content="I write about ideas, and the foundations that shape how we live.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:url" content="https://robertmarshall.xyz/writings/how-we-lost-control-and-learned-nothing/">
  <meta property="og:site_name" content="Robert Marshall">
  <meta property="og:title" content="How We Lost Control and Learned Nothing">
  <meta property="og:description" content="A philosophical examination of Stanley Kubrick’s Dr. Strangelove and its uncanny relevance to the growing existential threat of artificial intelligence, seen through the collapse of human responsibility into mechanised decision-making.">
  <meta property="og:locale" content="en_gb">
  <meta property="og:type" content="article">
    <meta property="article:section" content="writings">
    <meta property="article:published_time" content="2025-04-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-04-24T00:00:00+00:00">
    <meta property="article:tag" content="Artificial Intelligence">
    <meta property="article:tag" content="Eethics">
    <meta property="article:tag" content="Autonomy">
    <meta property="article:tag" content="Philosophy">
    <meta property="article:tag" content="Automation">
    <meta property="article:tag" content="Existential Risk">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="How We Lost Control and Learned Nothing">
  <meta name="twitter:description" content="A philosophical examination of Stanley Kubrick’s Dr. Strangelove and its uncanny relevance to the growing existential threat of artificial intelligence, seen through the collapse of human responsibility into mechanised decision-making.">

  
  
    
  
  
  <link rel="stylesheet" href="https://robertmarshall.xyz/css/styles.c05d68261bf086a9d7713c4f8a6215a3601608e267a816a7ee58f139b3d1aae51222aae2081c8e0c6bd35e1334773b7a16283022f31f92afd93bb37e5e822e66.css" integrity="sha512-wF1oJhvwhqnXcTxPimIVo2AWCOJnqBan7ljxObPRquUSIqriCByODGvTXhM0dzt6FigwIvMfkq/ZO7N&#43;XoIuZg=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" href="https://raw.githubusercontent.com/robertmarshallxyz/img/main/avatar.jpg" />
  
  
  

</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

    <header id="header">
  <a href="https://robertmarshall.xyz/">
  
    <div id="logo" style="background-image: url(https://robertmarshall.xyz/images/logo.png)"></div>
  
  <div id="title">
    <h1>Robert Marshall</h1>
  </div>
  </a>
  <div id="nav">
    <ul>
      <li class="icon">
        <a href="#" aria-label="Menu"><i class="fas fa-bars fa-2x" aria-hidden="true"></i></a>
      </li>
      
        <li><a href="/writings">Writings</a></li>
      
        <li><a href="/about">About</a></li>
      
        <li><a href="/contact">Contact</a></li>
      
    </ul>
  </div>
</header>



    
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <div class="content" itemprop="articleBody">
  
    <p><strong>How We Lost Control and Learned Nothing</strong></p>
<p>Stanley Kubrick’s <em>Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb</em> is often praised as a masterclass in satire, a barbed commentary on Cold War paranoia and military absurdity. But it is more than a film about nuclear weapons. It is a study in delegation—a portrait of what happens when men place machines between themselves and responsibility. Though made in 1964, long before neural nets and reinforcement learning, <em>Dr. Strangelove</em> is arguably more prescient about artificial intelligence than most of the fiction written with that label.</p>
<p>The Doomsday Machine, that silent engine of annihilation, is not merely a metaphor. It is the logical conclusion of removing human deliberation from catastrophic decisions. And it bears a troubling resemblance to the systems we are now building—opaque, complex, automatic—marketed as tools of liberation but designed, in practice, to bypass human agency altogether.</p>
<p>In the film, General Ripper circumvents protocol and unilaterally orders a nuclear strike. It is a lunatic act, but the greater madness lies in the system itself: one that allows a single man to initiate global destruction without oversight. Once the bombers are airborne, the mechanisms of annihilation function exactly as designed. The president cannot recall them. The Russians, for their part, have constructed their own Doomsday Device—an automated retaliatory mechanism that will wipe out all life if triggered. But they forgot to announce it. “The whole point of the Doomsday Machine is lost if you keep it a secret!” exclaims Dr. Strangelove.</p>
<p>What Kubrick understood—long before neural networks became fashionable—is that systems need not be sentient to be dangerous. They need only to be followed. And that is precisely what makes them terrifying.</p>
<p>We are now told that artificial intelligence will revolutionise warfare, medicine, law enforcement, finance. That it will optimise outcomes and reduce error. But the question that <em>Dr. Strangelove</em> forces us to ask—the one we are too often afraid to raise—is whether such decisions should be made at all. For a system that makes decisions quickly, without the burden of conscience or context, is not efficient. It is ungoverned.</p>
<p>The deeper threat posed by AI is not that it becomes evil, but that we become irrelevant. We are building structures of automated power, not because they are better than us, but because we have grown weary of responsibility. Bureaucracies love automation because it disperses blame. Politicians love it because it shields them from judgment. Corporations love it because it scales. But machines do not love us. They do not hate us, either. They do not care. And that is what makes them dangerous.</p>
<p>There is a telling moment in <em>Dr. Strangelove</em> when President Muffley, in a last-ditch effort to prevent the end of the world, tries to reason with the Soviet ambassador. The scene descends into farce: “Gentlemen, you can’t fight in here! This is the War Room!” But the absurdity is the point. The institutions built to protect humanity have collapsed under the weight of their own logic. Not because the systems failed—but because the humans abdicated their duty.</p>
<p>Today’s AI systems mirror the same trajectory. We are building tools whose decisions we cannot interpret, reverse, or meaningfully contest. We call them breakthroughs. But what they truly represent is a slow-motion surrender of the human role in decision-making. Just as the Doomsday Machine, once triggered, cannot be reasoned with or stopped, so too are we crafting systems whose complexity becomes an excuse for inaction. We no longer ask whether something is right. Only whether it is permitted by protocol.</p>
<p>The idea that we can delegate judgment to machines and retain moral clarity is a dangerous illusion. It is tempting, of course, because it absolves us. No one pulls the trigger. The code runs. The model infers. The outcome is delivered. We are spectators to our own power.</p>
<p>The final sequence of <em>Dr. Strangelove</em> shows the Earth’s destruction set to the tune of <em>We’ll Meet Again</em>. The images are horrific, but the tone is whimsical. That dissonance is Kubrick’s final indictment. The machinery of annihilation carries on, oblivious to the lives it ends. And the people who built it have long since stopped asking why.</p>
<p>AI, like the Doomsday Machine, doesn’t have to rebel. It only has to be obeyed. We are told it will free us from error—but it may instead free us from relevance. There is no need for malice. Only for compliance.</p>
<p>What <em>Dr. Strangelove</em> showed us is that the world ends not with a bang, but with a procedure. A checklist. An interface. A machine, programmed once, running as intended.</p>
<p>Today, we stand again in the War Room. The details have changed, but the dynamic has not. The real threat is not the machine. It is the man who believes the machine will do his thinking for him.</p>
<p>We ought to be afraid.</p>

  
  </div>
</article>


    <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2025  Robert Marshall 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/writings">Writings</a></li>
         
        <li><a href="/about">About</a></li>
         
        <li><a href="/contact">Contact</a></li>
        
        <li>
          <a class="icon" href="/atom.xml" aria-label="rss">
            <i class="fa fa-rss" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
    </nav>
  </div>
</footer>

  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
</html>
